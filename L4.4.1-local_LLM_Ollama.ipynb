{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ollama to set up LLM on premises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with `ollama` you can [download](https://ollama.com/download) and install its app or you can also mount a [docker image containing it](https://hub.docker.com/r/ollama/ollama).  In either case you will get an [API](https://github.com/ollama/ollama/blob/main/docs/api.md) with which you can interact with using its own [ollama python library](https://pypi.org/project/ollama/) or another third party tool such as [langchain](https://python.langchain.com/v0.2/docs/how_to/local_llms/#ollama).\n",
    "\n",
    " * When the app is running you must fetch a model from this list of options: e.g., ollama pull gemma2:2b\n",
    "    and all models are automatically served on *localhost:11434*\n",
    "   \n",
    " * The LLM model that we gonna load must already be fetched by **pull**\n",
    " * When the model is unused the memory used is released (less than 5 minutes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown  # to see better the output text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From ollama library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install ollama\n",
    "from ollama import Client\n",
    "\n",
    "client = Client(host='http://localhost:11434')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To pull a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.pull(model='gemma2:2b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'parent_model': '',\n",
       " 'format': 'gguf',\n",
       " 'family': 'gemma2',\n",
       " 'families': ['gemma2'],\n",
       " 'parameter_size': '2.6B',\n",
       " 'quantization_level': 'Q4_0'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.show(model='gemma2:2b')['details']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To delete a model\n",
    "https://github.com/ollama/ollama/blob/main/docs/api.md#delete-a-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete(model='gemma2:2b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Neil Armstrong** was the first man to walk on the Moon. \n",
       "\n",
       "He achieved this historic feat during the Apollo 11 mission on July 20, 1969.  His famous words upon stepping onto the lunar surface were: \"That's one small step for [a] man, one giant leap for mankind.\"\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat(model=\"gemma2:2b\", options={\"temperature\": 0.0}, messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'Who was the first man on the moon?',\n",
    "    },\n",
    "])\n",
    "Markdown(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Gemma2 in Ollama from langchain\n",
    "* https://ollama.com/library/gemma2:2b\n",
    "\n",
    "* It takes 3GB of GPU to make the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The first person to walk on the Moon was **Neil Armstrong**, an American astronaut, on July 20, 1969, during the Apollo 11 mission.  \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %pip install -qU langchain_ollama\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "llm = OllamaLLM(model=\"gemma2:2b\", temperature=0.0)\n",
    "\n",
    "Markdown(llm.invoke(\"'Who was the first man on the moom?\")) # moom: misspelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hi Alejandro! 👋  It's nice to meet you. 😊 \n",
       "\n",
       "What can I help you with today? 😄 \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(llm.invoke(\"hi, my name is alejandro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. Keep the answer concise.\\n Question: {query}\"\"\")\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Why is six afraid of seven? \n",
       "\n",
       "Because seven eight nine! 😂 \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = chain.invoke({\"query\": \"Tell me a funny joke about mathematics\"})\n",
    "Markdown(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Paris is the capital of France, known for its iconic landmarks like the Eiffel Tower and Louvre Museum. It boasts beautiful architecture, rich history, delicious cuisine, and vibrant culture. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = chain.invoke({\"query\": \"tell me about paris?\"})\n",
    "Markdown(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\"More recent implementations, such as Differential/Timely Dataflow, have used incremental computing for much more efficient data processing.\" \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = (\n",
    "\"Formally, a database refers to a set of related data accessed through the use of a\" \n",
    "\"database management system (DBMS), which is an integrated set of computer software that allows\"\n",
    "\"users to interact with one or more databases and provides access to all of the data contained in \"\n",
    "\"the database (although restrictions may exist that limit access to particular data). The DBMS \"\n",
    "\"provides various functions that allow entry, storage and retrieval of large quantities of \"\n",
    "\"information and provides ways to manage how that information is organized. High-performance \"\n",
    "\"computing is critical for the processing and analysis of data. One particularly widespread \"\n",
    "\"approach to computing for data engineering is dataflow programming, in which the computation is \"\n",
    "\"represented as a directed graph (dataflow graph); nodes are the operations, and edges represent \"\n",
    "\"the flow of data. Popular implementations include Apache Spark, and the deep learning specific \"\n",
    "\"TensorFlow. More recent implementations, such as Differential/Timely Dataflow, have used \"\n",
    "\"incremental computing for much more efficient data processing.\"\n",
    ")\n",
    "out = chain.invoke(\n",
    "    {\"query\": f\"What is the last sentence of the following text? \\n ```{text} ```\"})\n",
    "Markdown(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation and summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Formalmente, una base de datos se refiere a un conjunto de datos relacionados que se accede mediante un sistema de gestión de bases de datos (DBMS), que es un conjunto integrado de software informático que permite a los usuarios interactuar con una o más bases de datos y proporciona acceso a toda la información contenida en la base de datos (aunque pueden existir restricciones que limitan el acceso a ciertos datos). El DBMS proporciona varias funciones que permiten la entrada, almacenamiento y recuperación de grandes cantidades de información y proporciona formas de gestionar cómo está organizada esa información. La computación de alto rendimiento es crucial para el procesamiento y análisis de datos. Un enfoque particularmente extendido para la computación de ingeniería de datos es el programación de flujo de datos, en el cual la computación se representa como un gráfico dirigido (gráfico de flujo de datos); los nodos son las operaciones y los bordes representan el flujo de datos. Implementaciones populares incluyen Apache Spark y TensorFlow, específico para aprendizaje profundo. Implementaciones más recientes, como Differential/Timely Dataflow, han utilizado la computación incremental para un procesamiento de datos mucho más eficiente. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(llm.invoke(f\"can you translate to spanish the following text: {text}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "A database is a structured collection of related information accessed through a DBMS, which manages and organizes data while allowing users to interact with it.  Data engineering utilizes techniques like dataflow programming and advanced algorithms like TensorFlow to process and analyze large datasets efficiently. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(llm.invoke(f\"can you summary the following text in two sentences: {text}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Keep the answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ")\n",
    "rag_chain = rag_prompt|llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer with context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Dataflow programming represents computation as a directed graph where nodes are operations and edges represent data flow. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(rag_chain.invoke(\n",
    "    {\"query\": \"What is  dataflow programming? \", \"context\": text}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer without context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Dataflow Programming: A Stream of Data\n",
       "\n",
       "Dataflow programming is a paradigm where **data flows through the program**, driven by events and transformations. It's like a river, with data as water flowing from one point to another, undergoing various processes along the way. \n",
       "\n",
       "**Here's how it works:**\n",
       "\n",
       "1. **Data Sources:**  The journey starts with data sources (like sensors, databases, or files).\n",
       "2. **Processing Units:** These are \"nodes\" that perform operations on the data. Think of them as factories where raw materials are transformed into finished products. \n",
       "3. **Connections:** Data flows from source to processing unit and then to other units, forming a network of interconnected nodes. \n",
       "4. **Data Transformations:**  Processing units apply functions or algorithms to the data, changing its form and content. This is like adding value to raw materials in our factory analogy.\n",
       "5. **Outputs:** The transformed data flows out from processing units, ready for further use or storage.\n",
       "\n",
       "**Key Features of Dataflow Programming:**\n",
       "\n",
       "* **Parallelism:**  Dataflow programs can process multiple data streams simultaneously, making them highly efficient and scalable. \n",
       "* **Event-Driven:**  The program reacts to events (like new data arriving) and executes the necessary transformations accordingly. This makes it responsive and adaptable.\n",
       "* **Declarative:** You describe what you want the program to do without specifying how to achieve it. The system handles the details of execution.\n",
       "\n",
       "**Benefits of Dataflow Programming:**\n",
       "\n",
       "* **Increased Efficiency:**  Parallel processing leads to faster execution times, especially for complex tasks involving large datasets. \n",
       "* **Simplified Development:**  Focus on data flow and transformations instead of low-level control, making development easier and more intuitive.\n",
       "* **Flexibility:**  Adaptable to changing requirements as new data sources or processing units can be easily added.\n",
       "\n",
       "**Examples of Dataflow Programming:**\n",
       "\n",
       "* **Data Streaming:** Processing real-time data streams from sensors, IoT devices, or social media feeds. \n",
       "* **Machine Learning:** Training and deploying machine learning models on large datasets.\n",
       "* **Signal Processing:** Analyzing audio, video, or sensor signals for various applications like image recognition or speech synthesis.\n",
       "\n",
       "\n",
       "**In Summary:**\n",
       "\n",
       "Dataflow programming is a powerful approach to building software that handles massive amounts of data efficiently and flexibly. It's ideal for tasks where speed, scalability, and adaptability are crucial. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(llm.invoke(\"What is  dataflow programming?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Phi2:mini-4k in Ollama from langchain\n",
    "* https://ollama.com/library/phi3:mini-4k\n",
    "* It takes 6GB of GPU to make the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'success'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.pull(model='phi3:mini-4k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'parent_model': '',\n",
       " 'format': 'gguf',\n",
       " 'family': 'phi3',\n",
       " 'families': ['phi3'],\n",
       " 'parameter_size': '3.8B',\n",
       " 'quantization_level': 'Q4_K_M'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.show(model='phi3:mini-4k')['details']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The phrase \"the first man on the moon\" refers to astronaut Neil Armstrong, who became the first human to set foot on the lunar surface during NASA's Apollo 11 mission. This historic event took place on July 20, 1969."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %pip install -qU langchain_ollama\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "llm_phi = OllamaLLM(model=\"phi3:mini-4k\", temperature=0.0)\n",
    "\n",
    "Markdown(llm_phi.invoke(\"'Who was the first man on the moom?\")) # moom: misspelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello Alejandro! How can I assist you today?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(llm_phi.invoke(\"hi, my name is alejandro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. Keep the answer concise.\\n Question: {query}\"\"\")\n",
    "\n",
    "chain = prompt | llm_phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Why did the math book look so sad? Because it had too many problems!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = chain.invoke({\"query\": \"Tell me a funny joke about mathematics\"})\n",
    "Markdown(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Paris, known as \"The City of Light,\" is a global center for art, fashion, gastronomy, and culture. Its 19th-century cityscape is crisscrossed by wide boulevards and the River Seine. The Eiffel Tower, an iconic symbol of France, stands tall in its heart. Paris has been one of Europe's major cities since the Middle Avestrian Age (around AD 50). It was a center for education with institutions like Sorbonne University founded here during medieval times and later became known as \"The City of Light\" due to it being among the first large European cities to use gas street lighting."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = chain.invoke({\"query\": \"tell me about paris?\"})\n",
    "Markdown(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The text does not provide a last sentence explicitly; it ends with information about popular implementations of dataflow programming like Apache Spark and TensorFlow before mentioning newer approaches without concluding the paragraph or statement."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = (\n",
    "\"Formally, a database refers to a set of related data accessed through the use of a\" \n",
    "\"database management system (DBMS), which is an integrated set of computer software that allows\"\n",
    "\"users to interact with one or more databases and provides access to all of the data contained in \"\n",
    "\"the database (although restrictions may exist that limit access to particular data). The DBMS \"\n",
    "\"provides various functions that allow entry, storage and retrieval of large quantities of \"\n",
    "\"information and provides ways to manage how that information is organized. High-performance \"\n",
    "\"computing is critical for the processing and analysis of data. One particularly widespread \"\n",
    "\"approach to computing for data engineering is dataflow programming, in which the computation is \"\n",
    "\"represented as a directed graph (dataflow graph); nodes are the operations, and edges represent \"\n",
    "\"the flow of data. Popular implementations include Apache Spark, and the deep learning specific \"\n",
    "\"TensorFlow. More recent implementations, such as Differential/Timely Dataflow, have used \"\n",
    "\"incremental computing for much more efficient data processing.\"\n",
    ")\n",
    "out = chain.invoke(\n",
    "    {\"query\": f\"What is the last sentence of the following text? \\n ```{text} ```\"})\n",
    "Markdown(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation and summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Formalmente, un sistema de base de datos se refiere a un conjunto de datos relacionados accesibles mediante el uso de una Base de Datos Management System (DBMS), que es un conjunto integrado de software informático que permite la interacción con uno o más sistemas de bases de datos y proporciona acceso a toda la información contenida en ellos (si bien pueden existir restricciones que limitan el acceso a ciertos datos). El DBMS ofrece diversas funciones que permiten la entrada, almacenamiento y recuperación de grandes cantidades de información e incluye formas para gestionar cómo esa información está organizada. La computación en alta capacidad es crítica para el procesamiento y análisis de datos. Una aproximación particularmente extendida a la programación para ingeniería de datos es la programación basada en flujo, donde se representa la computación como un grafo dirigido (grafo de flujos); los nodos son las operaciones y las aristas representan el flujo de datos. Implementaciones populares incluyen Apache Spark e TensorFlow específico para aprendizaje profundo. Más recientemente, implementaciones como Differential/Timely Dataflow han utilizado la computación incremental para un procesamiento mucho más eficiente del mismo."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(llm_phi.invoke(f\"can you translate to spanish the following text: {text}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "A database management system (DBMS) is a software that allows users to interact with databases by providing functions for entry, storage and retrieval of large quantities of information while managing its organization; high-performance computing plays an essential role in this process. Dataflow programming represents computation as directed graphs where nodes are operations and edges represent data flow—Apache Spark and TensorFlow being popular implementations, with newer ones like Differential/Timely Dataflow using incremental computing for efficient processing of large datasets."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(llm_phi.invoke(f\"can you summary the following text in two sentences: {text}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Keep the answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ")\n",
    "rag_chain = rag_prompt|llm_phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer with context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Dataflow programming is a paradigm where computation models are represented by directed graphs (dataflow graphs), with nodes representing operations and edges indicating the flow of data between these operations. This approach allows parallel execution, as different parts of the graph can be processed simultaneously if they do not depend on each other's results. It enables efficient processing for large-scale computations in fields like big data analytics and machine learning by optimizing resource utilization and reducing latency through incremental computing techniques such as those used in Differential/Timely Dataflow implementations, which are more recent advanc employee satisfaction can be measured using various methods. One common approach is conducting surveys or questionnaires that assess employees' attitudes towards their work environment, job roles, and the organization itself. These tools often include questions about engagement levels, motivation, perceived support from management, opportunities for growth, recognition of achievements, work-life balance, and overall satisfaction with their jobs.\n",
       "\n",
       "Another method is through interviews or focus groups that allow employees to discuss in more depth the factors contributing to their job satisfaction. This qualitative approach can provide deeper insights into employee sentiments and experiences within an organization. Additionally, performance metrics such as turnover rates, absenteeism, productivity levels, and quality of work output are indirect indicators of overall employee morale and engagement.\n",
       "\n",
       "Organizations may also use more sophisticated tools like the Job Descriptive Index (JDI) or the Minnesota Satisfaction Questionnaire (MSQ), which have been developed specifically to measure job satisfaction across various dimensions systematically. These instruments are designed based on psychological theories of motivation and well-being, ensuring that they capture a comprehensive picture of employee attitudes towards their work life.\n",
       "\n",
       "It's important for organizations to regularly assess employee morale as it can significantly impact productivity, retention rates, customer satisfaction, and overall organizational success."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(rag_chain.invoke(\n",
    "    {\"query\": \"What is  dataflow programming? \", \"context\": text}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer without context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Dataflow programming is a model of computation where the program's control flow depends on the availability and state of various pieces of data. In this paradigm, programs are composed of nodes representing operations or computations that process input data to produce output results. The execution proceeds by passing values from one node (or operation) to another along a directed graph called a \"dataflow network\" until all the required inputs have been processed and their corresponding outputs can be produced.\n",
       "\n",
       "The key characteristics of dataflow programming include:\n",
       "\n",
       "1. Declarative nature: Dataflow programs are typically written in a declarative manner, where you specify what needs to be done rather than how it should be done (as opposed to imperative languages). This makes the code more readable and easier to understand since each operation is clearly defined with its inputs and outputs.\n",
       "2. Asynchronous execution: Since dataflow programs are event-driven by nature, they can execute asynchronously without blocking other operations waiting for their turn in a sequential manner (as seen in traditional imperative programming). This allows better utilization of resources like CPUs or GPUs since multiple computations may be performed simultaneously.\n",
       "3. Dynamic execution: Dataflow programs are dynamic and adaptable to changes, meaning that the program can adjust its behavior based on available data at runtime without requiring explicit reconfiguration by a programmer (as seen in static programming models). This makes it easier for developers to create flexible applications capable of handling various scenarios or inputs efficiently.\n",
       "4. Parallelism: Dataflow programs are inherently parallelizable since different operations may be executed simultaneously, depending on the availability and dependencies between data nodes within their network structure. By exploiting this property effectively (e.g., using multi-core processors), developers can achieve significant performance improvements in computationally intensive tasks or large datasets processing applications like image/video analysis, machine learning algorithms, etc.\n",
       "5. Highly modular: Dataflow programs are composed of independent nodes that represent discrete operations on data elements; this makes it easier to reuse and compose existing components (e.g., libraries) within new systems without worrying about the underlying implementation details or dependencies between different parts of a program's execution flow.\n",
       "6. Efficient resource utilization: Since each node in a dataflow network operates independently, only those nodes that have available input data will be executed at any given time (as opposed to traditional programming models where all operations may need to execute sequentially). This leads to better CPU/GPU usage and reduced power consumption when processing large datasets or complex computations.\n",
       "7. Easy debugging: Debugging a dataflow program can often involve tracing the flow of input values through various nodes in its network structure until their corresponding outputs are produced (as opposed to traditional programming models where bugs may be harder to pinpoint due to interdependencies between different parts). This makes it easier for developers and users alike to understand how an application works or identify potential issues within a given system.\n",
       "8. Scalability: Dataflow programs can scale well across multiple processing units (e. employee) since each node operates independently, allowing them to be distributed over various hardware resources without affecting the overall execution flow of other nodes in their network structure. This makes it easier for developers and organizations alike to build scalable systems capable of handling large datasets or computationally intensive tasks efficiently while maintaining high performance levels even under heavy loads (e.g., real-time data processing applications).\n",
       "9. Flexibility: Dataflow programming models are highly flexible since they allow programmers to define their own custom operations and combine them in various ways within a network structure depending on the specific requirements of an application or problem domain being addressed by developers/organizations alike (e.g., creating specialized algorithms for image processing tasks).\n",
       "10. Ease-of-use: Dataflow programming models are often easier to learn than traditional imperative languages since they focus more on specifying what needs to be done rather than how it should be done; this makes them suitable for beginners or non-programmers who want to create simple applications without having extensive knowledge of computer science concepts like algorithms, data structures etc.\n",
       "In summary, Dataflow programming is a powerful paradigm that offers numerous benefits such as parallelism, modularity, efficient resource utilization and scalability among others which make it an attractive choice for developing complex systems capable of handling large datasets or computationally intensive tasks efficiently while maintaining high performance levels even under heavy loads."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(llm_phi.invoke(\"What is  dataflow programming?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
